{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d304964",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11089,
     "status": "ok",
     "timestamp": 1767070980856,
     "user": {
      "displayName": "이예서",
      "userId": "03659744198424161652"
     },
     "user_tz": -540
    },
    "id": "3d304964",
    "outputId": "125c202b-bffb-4f0d-adbb-c52f243444bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch_geometric in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from torch_geometric) (4.64.1)\n",
      "Requirement already satisfied: requests in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from torch_geometric) (2.28.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from torch_geometric) (3.6.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from torch_geometric) (5.9.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from torch_geometric) (3.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from torch_geometric) (1.23.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from torch_geometric) (2022.11.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from torch_geometric) (3.0.9)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from torch_geometric) (3.13.2)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (1.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (1.8.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (2.6.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (1.22.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (22.1.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from jinja2->torch_geometric) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from tqdm->torch_geometric) (0.4.6)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e97093c3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10723,
     "status": "ok",
     "timestamp": 1767070991582,
     "user": {
      "displayName": "이예서",
      "userId": "03659744198424161652"
     },
     "user_tz": -540
    },
    "id": "e97093c3",
    "outputId": "b07131c9-5637-4c6f-f038-4e79a6596cb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (1.12.1)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.24.1-cp310-cp310-win_amd64.whl (3.7 MB)\n",
      "     ---------------------------------------- 3.7/3.7 MB 9.1 MB/s eta 0:00:00\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.9.1-cp310-cp310-win_amd64.whl (663 kB)\n",
      "     ------------------------------------- 663.9/663.9 kB 10.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Collecting torch\n",
      "  Downloading torch-2.9.1-cp310-cp310-win_amd64.whl (111.0 MB)\n",
      "     -------------------------------------- 111.0/111.0 MB 6.4 MB/s eta 0:00:00\n",
      "Collecting typing_extensions\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "     ---------------------------------------- 44.6/44.6 kB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from torch) (2022.11.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Collecting sympy>=1.13.3\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "     ---------------------------------------- 6.3/6.3 MB 11.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ansh1\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Installing collected packages: typing_extensions, sympy, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.11.1\n",
      "    Uninstalling sympy-1.11.1:\n",
      "      Successfully uninstalled sympy-1.11.1\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.1\n",
      "    Uninstalling torch-1.12.1:\n",
      "      Successfully uninstalled torch-1.12.1\n",
      "Successfully installed sympy-1.14.0 torch-2.9.1 torchaudio-2.9.1 torchvision-0.24.1 typing_extensions-4.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "oJNCYF_NopHu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12182,
     "status": "ok",
     "timestamp": 1767070955289,
     "user": {
      "displayName": "이예서",
      "userId": "03659744198424161652"
     },
     "user_tz": -540
    },
    "id": "oJNCYF_NopHu",
    "outputId": "0f2ed1d4-d130-40e4-8e49-2a1c0b84c43a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rdkit\n",
      "  Downloading rdkit-2025.9.3-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rdkit) (2.0.2)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit) (11.3.0)\n",
      "Downloading rdkit-2025.9.3-cp312-cp312-manylinux_2_28_x86_64.whl (36.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rdkit\n",
      "Successfully installed rdkit-2025.9.3\n"
     ]
    }
   ],
   "source": [
    "!pip install rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59f7ef74",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1767073028282,
     "user": {
      "displayName": "이예서",
      "userId": "03659744198424161652"
     },
     "user_tz": -540
    },
    "id": "59f7ef74"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data, Dataset, DataLoader\n",
    "from torch_geometric.nn import global_add_pool\n",
    "from torch_cluster import radius_graph\n",
    "from tqdm import tqdm\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, rdchem\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50928b09",
   "metadata": {},
   "source": [
    "환경결정상수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "758190fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H5 파일 키 설정\n",
    "KEY_CONFIG = {\n",
    "    \"atoms\": \"elements\", \"smiles\": \"Rsmiles\",\n",
    "    \"R_coords\": \"RG\", \"TS_coords\": \"TSG\", \"P_coords\": \"PG\",          \n",
    "    \"R_energy\": { \"H\": \"R_H\", \"G\": \"R_F\", \"E\": \"R_E\" },\n",
    "    \"TS_energy\": { \"H\": \"TS_H\", \"G\": \"TS_F\", \"E\": \"TS_E\" },\n",
    "    \"P_energy\": { \"H\": \"P_H\", \"G\": \"P_F\", \"E\": \"P_E\" }\n",
    "}\n",
    "\n",
    "# 결합 해리 에너지 (BDE) 테이블 (kcal/mol)\n",
    "BDE_TABLE = {\n",
    "    (1, 1): 104, (1, 6): 99, (1, 7): 93, (1, 8): 111, (1, 9): 135,\n",
    "    (6, 6): 83, (6, 7): 73, (6, 8): 86, (6, 9): 116,\n",
    "    (7, 7): 39, (7, 8): 53, (8, 8): 35\n",
    "}\n",
    "\n",
    "# 원자 물성 [EN, Hardness, Radius, IE]\n",
    "ATOM_PROPS_TABLE = {\n",
    "    1: [2.20, 6.42, 0.31, 13.60], 6: [2.55, 5.00, 0.76, 11.26],\n",
    "    7: [3.04, 7.27, 0.71, 14.53], 8: [3.44, 6.08, 0.66, 13.62], 9: [3.98, 7.01, 0.57, 17.42]\n",
    "}\n",
    "DEFAULT_PROPS = [0.0, 0.0, 0.0, 0.0]\n",
    "\n",
    "# 작용기 SMARTS 패턴\n",
    "FUNCTIONAL_GROUPS = {\n",
    "    \"Nitro\": \"[N+](=O)[O-]\", \"Sulfonyl\": \"S(=O)(=O)\", \"Cyano\": \"C#N\", \"Trifluoromethyl\": \"C(F)(F)F\",\n",
    "    \"Carbonyl\": \"[CX3]=[OX1]\", \"Carboxyl\": \"[CX3](=O)[OX2H1]\", \"Halogen\": \"[F,Cl,Br,I]\",\n",
    "    \"Amine\": \"[NX3;H2,H1,H0;!$(NC=O)]\", \"Hydroxy\": \"[OX2H]\", \"Alkoxy\": \"[OX2][CX4]\", \n",
    "    \"Amide\": \"[NX3][CX3](=O)\", \"Alkyl\": \"[CX4]\", \"Phenyl\": \"c1ccccc1\"\n",
    "}\n",
    "FG_TYPE_MAP = {\n",
    "    \"Nitro\": -1.0, \"Sulfonyl\": -1.0, \"Cyano\": -1.0, \"Trifluoromethyl\": -1.0,\n",
    "    \"Carbonyl\": -0.5, \"Carboxyl\": -0.5, \"Halogen\": -0.2, \"Amine\": 1.0, \"Hydroxy\": 1.0, \n",
    "    \"Alkoxy\": 1.0, \"Amide\": 0.2, \"Alkyl\": 0.3, \"Phenyl\": 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ce4925",
   "metadata": {
    "id": "30ce4925"
   },
   "source": [
    "데이터셋 (T1x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20f28c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transition1xDataset(Dataset):\n",
    "    def __init__(self, h5_path, limit=10000):\n",
    "        super().__init__(None, None)\n",
    "        self.data_list = []\n",
    "        self.limit = limit\n",
    "        \n",
    "        # RGD1과 동일한 Feature 생성을 위한 매핑 테이블\n",
    "        self.sym_map = {1: 0, 6: 1, 7: 2, 8: 3, 9: 4} \n",
    "        self.mass_map = {1: 1.008, 6: 12.011, 7: 14.007, 8: 15.999, 9: 18.998}\n",
    "        \n",
    "        self.load_data(h5_path)\n",
    "\n",
    "    def get_dummy_features(self, atomic_numbers):\n",
    "        \"\"\"\n",
    "        원자 번호를 받아 RGD1 모델과 호환되는 27차원 Dummy Feature를 생성합니다.\n",
    "        \"\"\"\n",
    "        num_atoms = len(atomic_numbers)\n",
    "        features = torch.zeros((num_atoms, 27), dtype=torch.float)\n",
    "        \n",
    "        for i, z_val in enumerate(atomic_numbers):\n",
    "            z = int(z_val.item())\n",
    "            idx = self.sym_map.get(z, 5) \n",
    "            if idx < 6:\n",
    "                features[i, idx] = 1.0\n",
    "            mass = self.mass_map.get(z, 12.0)\n",
    "            features[i, 14] = mass / 20.0\n",
    "            \n",
    "        return features\n",
    "\n",
    "    def load_data(self, h5_path):\n",
    "        print(f\"Loading Transition1x Data from {h5_path} (Limit: {self.limit})...\")\n",
    "        \n",
    "        try:\n",
    "            with h5py.File(h5_path, \"r\") as f:\n",
    "                if 'data' not in f:\n",
    "                    print(\"Error: 'data' key not found in h5 file.\")\n",
    "                    return\n",
    "                \n",
    "                split = f['data']\n",
    "                count = 0\n",
    "                \n",
    "                for formula in tqdm(split.keys(), desc=\"Parsing T1x\"):\n",
    "                    if count >= self.limit: break\n",
    "                    \n",
    "                    grp = split[formula]\n",
    "                    for rxn in grp.keys():\n",
    "                        if count >= self.limit: break\n",
    "                        \n",
    "                        subgrp = grp[rxn]\n",
    "                        try:\n",
    "                            z = torch.tensor(subgrp['atomic_numbers'], dtype=torch.long)\n",
    "                            x_feat = self.get_dummy_features(z)\n",
    "                            \n",
    "                            pos_R = torch.tensor(subgrp['reactant']['positions'][-1], dtype=torch.float)\n",
    "                            pos_P = torch.tensor(subgrp['product']['positions'][-1], dtype=torch.float)\n",
    "                            pos_TS = torch.tensor(subgrp['transition_state']['positions'][-1], dtype=torch.float)\n",
    "                            \n",
    "                            data = Data(x=x_feat, z=z, pos=pos_R, y_pos=pos_TS, pos_P=pos_P)\n",
    "                            \n",
    "                            num_nodes = z.size(0)\n",
    "                            data.edge_index = radius_graph(pos_R, r=5.0, max_num_neighbors=50)\n",
    "                            num_edges = data.edge_index.size(1)\n",
    "                            \n",
    "                            data.hsab = torch.zeros((num_nodes, 2), dtype=torch.float) \n",
    "                            data.edge_bde = torch.zeros((num_edges, 1), dtype=torch.float)\n",
    "                            \n",
    "                            # [핵심 수정] Shape를 (1, 1) -> (1, 3)으로 변경 (H, G, E 채널 맞춤)\n",
    "                            data.y_fwd = torch.zeros((1,1), dtype=torch.float)\n",
    "                            data.y_rev = torch.zeros((1,1), dtype=torch.float)\n",
    "                            data.thermo_energy = torch.zeros((1, 3), dtype=torch.float) \n",
    "                            \n",
    "                            self.data_list.append(data)\n",
    "                            count += 1\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            continue\n",
    "                            \n",
    "        except Exception as e:\n",
    "            print(f\"File Load Error: {e}\")\n",
    "        \n",
    "        print(f\"Loaded {len(self.data_list)} reactions for Pre-training.\")\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def get(self, idx):\n",
    "        return self.data_list[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66decd66",
   "metadata": {},
   "source": [
    "데이터셋 (RGD1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db02625a",
   "metadata": {
    "executionInfo": {
     "elapsed": 184,
     "status": "ok",
     "timestamp": 1767073031425,
     "user": {
      "displayName": "이예서",
      "userId": "03659744198424161652"
     },
     "user_tz": -540
    },
    "id": "db02625a"
   },
   "outputs": [],
   "source": [
    "class ReactionDataset(Dataset):\n",
    "    def __init__(self, h5_path, limit=None):\n",
    "        super().__init__(None, transform=None, pre_transform=None)\n",
    "        self.h5_path = h5_path\n",
    "        if not os.path.exists(h5_path): raise FileNotFoundError(f\"File not found: {h5_path}\")\n",
    "        with h5py.File(self.h5_path, 'r') as f:\n",
    "            self.keys = list(f.keys())\n",
    "            if limit: self.keys = self.keys[:limit]\n",
    "            self.len_data = len(self.keys)\n",
    "        self.fg_patterns = {name: Chem.MolFromSmarts(smarts) for name, smarts in FUNCTIONAL_GROUPS.items()}\n",
    "\n",
    "    def len(self): return self.len_data\n",
    "\n",
    "    def get_atom_features(self, mol):\n",
    "        try: AllChem.ComputeGasteigerCharges(mol); \n",
    "        except:\n",
    "            pass\n",
    "        features, hsab_list = [], []\n",
    "        \n",
    "        # 작용기(Functional Group) 탐지\n",
    "        atom_fg_info = {atom.GetIdx(): {'ewg':0.0, 'edg':0.0, 'types':[]} for atom in mol.GetAtoms()}\n",
    "        for name, pattern in self.fg_patterns.items():\n",
    "            if pattern:\n",
    "                for match in mol.GetSubstructMatches(pattern):\n",
    "                    effect = FG_TYPE_MAP.get(name, 0.0)\n",
    "                    for idx in match:\n",
    "                        if effect < 0: atom_fg_info[idx]['ewg'] += abs(effect)\n",
    "                        elif effect > 0: atom_fg_info[idx]['edg'] += effect\n",
    "                        atom_fg_info[idx]['types'].append(name)\n",
    "        \n",
    "        atoms_with_map = [(a.GetAtomMapNum() if a.GetAtomMapNum()!=0 else a.GetIdx()+1, a) for a in mol.GetAtoms()]\n",
    "        atoms_with_map.sort(key=lambda x: x[0])\n",
    "        \n",
    "        for _, atom in atoms_with_map:\n",
    "            feat = []\n",
    "            z = atom.GetAtomicNum()\n",
    "            idx = atom.GetIdx()\n",
    "            \n",
    "            # [1] Basic Info (21 dims)\n",
    "            sym_map={'H':0,'C':1,'N':2,'O':3,'F':4}; oh=[0]*6; oh[sym_map.get(atom.GetSymbol(),5)]=1; feat.extend(oh)\n",
    "            hyb=atom.GetHybridization(); hyb_map={rdchem.HybridizationType.SP:0, rdchem.HybridizationType.SP2:1, rdchem.HybridizationType.SP3:2, rdchem.HybridizationType.SP3D:3, rdchem.HybridizationType.SP3D2:4}; hyb_vec=[0]*5; \n",
    "            if hyb in hyb_map: hyb_vec[hyb_map[hyb]]=1\n",
    "            feat.extend(hyb_vec)\n",
    "            try: q=float(atom.GetProp('_GasteigerCharge')); \n",
    "            except: q=0.0\n",
    "            if np.isnan(q): q=0.0\n",
    "            feat.extend([q, float(atom.GetFormalCharge()), float(atom.GetTotalValence()), atom.GetMass()/20.0])\n",
    "            feat.extend([1.0 if atom.IsInRingSize(s) else 0.0 for s in [3,4,5,6]])\n",
    "            feat.extend([1.0 if atom.GetIsAromatic() else 0.0, 1.0 if atom.GetChiralTag()!=rdchem.ChiralType.CHI_UNSPECIFIED else 0.0])\n",
    "            \n",
    "            # [2] Functional Group Info (6 dims)\n",
    "            info = atom_fg_info[idx]\n",
    "            feat.extend([info['ewg'], info['edg'], 1.0 if 'Nitro' in info['types'] or 'Sulfonyl' in info['types'] else 0.0, 1.0 if 'Carbonyl' in info['types'] else 0.0, 1.0 if 'Amine' in info['types'] or 'Hydroxy' in info['types'] else 0.0, 1.0 if 'Halogen' in info['types'] else 0.0])\n",
    "            features.append(feat)\n",
    "            \n",
    "            # [3] HSAB Props\n",
    "            props = ATOM_PROPS_TABLE.get(z, DEFAULT_PROPS)\n",
    "            hsab_list.append([-props[0], props[1]]) # [Chemical Potential, Hardness]\n",
    "            \n",
    "        return torch.tensor(features, dtype=torch.float), torch.tensor(hsab_list, dtype=torch.float)\n",
    "\n",
    "    def get(self, idx):\n",
    "        with h5py.File(self.h5_path, 'r') as f:\n",
    "            group = f[self.keys[idx]]\n",
    "            \n",
    "            # RDKit Parsing\n",
    "            if KEY_CONFIG[\"smiles\"] in group:\n",
    "                smi = group[KEY_CONFIG[\"smiles\"]][()]; smi = smi.decode('utf-8') if isinstance(smi, bytes) else str(smi)\n",
    "                mol = Chem.MolFromSmiles(smi)\n",
    "                if mol: mol = Chem.AddHs(mol); x, hsab = self.get_atom_features(mol)\n",
    "                else: atoms = group[KEY_CONFIG[\"atoms\"]][()]; x = torch.zeros(len(atoms), 27); hsab = torch.zeros(len(atoms), 2)\n",
    "            else: atoms = group[KEY_CONFIG[\"atoms\"]][()]; x = torch.zeros(len(atoms), 27); hsab = torch.zeros(len(atoms), 2)\n",
    "            \n",
    "            # Coordinates\n",
    "            pos_R = torch.tensor(group[KEY_CONFIG[\"R_coords\"]][()], dtype=torch.float)\n",
    "            pos_TS = torch.tensor(group[KEY_CONFIG[\"TS_coords\"]][()], dtype=torch.float)\n",
    "            pos_P = torch.tensor(group[KEY_CONFIG[\"P_coords\"]][()], dtype=torch.float)\n",
    "            \n",
    "            # Energies\n",
    "            e_R = torch.tensor([group[KEY_CONFIG[\"R_energy\"][k]][()] for k in [\"H\",\"G\",\"E\"]], dtype=torch.float)\n",
    "            e_TS = torch.tensor([group[KEY_CONFIG[\"TS_energy\"][k]][()] for k in [\"H\",\"G\",\"E\"]], dtype=torch.float)\n",
    "            e_P = torch.tensor([group[KEY_CONFIG[\"P_energy\"][k]][()] for k in [\"H\",\"G\",\"E\"]], dtype=torch.float)\n",
    "            \n",
    "            # Targets (Delta Learning ready: predicting barriers directly)\n",
    "            y_fwd = (e_TS - e_R).unsqueeze(0)\n",
    "            y_rev = (e_TS - e_P).unsqueeze(0)\n",
    "            thermo = (e_P - e_R).unsqueeze(0)\n",
    "            \n",
    "            # Consistency Check\n",
    "            if x.size(0)!=pos_R.size(0): m=min(x.size(0),pos_R.size(0)); x=x[:m]; hsab=hsab[:m]; pos_R=pos_R[:m]; pos_P=pos_P[:m]; pos_TS=pos_TS[:m]\n",
    "            \n",
    "            # Fully Connected Edges\n",
    "            n=x.size(0); r=torch.arange(n).repeat_interleave(n); c=torch.arange(n).repeat(n); mask=r!=c\n",
    "            edge_index=torch.stack([r[mask], c[mask]], dim=0)\n",
    "            \n",
    "            # BDE Features\n",
    "            sym=torch.argmax(x[:,:6], dim=1); map_z={0:1,1:6,2:7,3:8,4:9,5:0}; z=torch.tensor([map_z.get(i.item(),0) for i in sym], dtype=torch.long)\n",
    "            bde = [BDE_TABLE.get(tuple(sorted((int(z[i]), int(z[j])))), 80.0) for i,j in edge_index.T]\n",
    "            edge_bde = torch.tensor(bde, dtype=torch.float).unsqueeze(-1)\n",
    "            \n",
    "            return Data(x=x, z=z, hsab=hsab, pos=pos_R, pos_P=pos_P, edge_index=edge_index, \n",
    "                        y_fwd=y_fwd, y_rev=y_rev, y_pos=pos_TS, thermo_energy=thermo, edge_bde=edge_bde)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14fddbb",
   "metadata": {
    "id": "b14fddbb"
   },
   "source": [
    "GNN Backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ea06084",
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1767073042127,
     "user": {
      "displayName": "이예서",
      "userId": "03659744198424161652"
     },
     "user_tz": -540
    },
    "id": "8ea06084"
   },
   "outputs": [],
   "source": [
    "class RBFLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    [Radial Basis Function Layer]\n",
    "    거리 정보를 단순히 하나의 숫자가 아닌, 여러 개의 기저 함수(Gaussian)로 확장하여 표현합니다.\n",
    "    이는 Geometric Deep Learning (SchNet, DimeNet)의 핵심 요소입니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_rbf=50, cutoff=5.0):\n",
    "        super().__init__()\n",
    "        self.cutoff = cutoff\n",
    "        # 0 ~ cutoff 사이를 num_rbf 개수만큼 등분\n",
    "        self.centers = nn.Parameter(torch.linspace(0, cutoff, num_rbf), requires_grad=False)\n",
    "        self.widths = nn.Parameter(torch.tensor([cutoff / num_rbf] * num_rbf), requires_grad=False)\n",
    "\n",
    "    def forward(self, dist):\n",
    "        # Gaussian Smearing: exp(- (d - mu)^2 / beta)\n",
    "        return torch.exp(-((dist - self.centers) ** 2) / self.widths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d3fed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeometricInteractionLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    [Geometric Interaction Block]\n",
    "    RBF로 확장된 거리 정보를 이용하여 노드 간의 상호작용을 학습합니다.\n",
    "    Simple MLP보다 훨씬 풍부한 기하학적 특징을 추출합니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim, num_rbf=50):\n",
    "        super().__init__()\n",
    "        self.rbf_lin = nn.Linear(num_rbf, hidden_dim)\n",
    "        \n",
    "        # Message Passing MLPs\n",
    "        self.msg_net = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        self.update_net = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "    def forward(self, h, edge_index, rbf_dist):\n",
    "        row, col = edge_index\n",
    "        \n",
    "        # 1. 거리 정보 변환 (RBF -> Hidden)\n",
    "        edge_geom = self.rbf_lin(rbf_dist) # [E, Hidden]\n",
    "        \n",
    "        # 2. 메시지 생성 (Source + Target) * Geometry\n",
    "        # SchNet 방식의 Continuous Filter Convolution 아이디어 차용\n",
    "        node_feat = torch.cat([h[row], h[col]], dim=-1)\n",
    "        msg_raw = self.msg_net(node_feat)\n",
    "        msg = msg_raw * edge_geom # Element-wise multiplication with Geometry\n",
    "        \n",
    "        # 3. 집계 (Aggregation)\n",
    "        aggr = torch.zeros_like(h)\n",
    "        aggr.index_add_(0, row, msg)\n",
    "        \n",
    "        # 4. 업데이트 (Update)\n",
    "        update = self.update_net(torch.cat([h, aggr], dim=-1))\n",
    "        \n",
    "        return self.norm(h + update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ce2b392",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeometricGNN(nn.Module):\n",
    "    \"\"\"\n",
    "    [Main Backbone]\n",
    "    위상학적 정보뿐만 아니라 기하학적(RBF) 정보를 적극 활용하는 GNN입니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, node_dim, hidden_dim, num_layers=4):\n",
    "        super().__init__()\n",
    "        self.node_emb = nn.Linear(node_dim, hidden_dim)\n",
    "        self.rbf = RBFLayer(num_rbf=50, cutoff=10.0)\n",
    "        self.layers = nn.ModuleList([\n",
    "            GeometricInteractionLayer(hidden_dim, num_rbf=50) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, pos, edge_index):\n",
    "        h = self.node_emb(x)\n",
    "        \n",
    "        # 거리 계산 및 RBF 변환\n",
    "        row, col = edge_index\n",
    "        dist = (pos[row] - pos[col]).norm(dim=-1, keepdim=True)\n",
    "        rbf_feat = self.rbf(dist) # [E, 50]\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            h = layer(h, edge_index, rbf_feat)\n",
    "            \n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "273d8a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigmoidGating(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.gate_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2 + 1, hidden_dim), nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, 1) \n",
    "        )\n",
    "    def forward(self, h, edge_index, pos):\n",
    "        row, col = edge_index\n",
    "        dist = (pos[row] - pos[col]).norm(dim=-1, keepdim=True)\n",
    "        # Logits 반환\n",
    "        return self.gate_mlp(torch.cat([h[row], h[col], dist], dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30f0ff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StructureDecoder(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(nn.Linear(hidden_dim*2, hidden_dim), nn.SiLU(), nn.Linear(hidden_dim, 1))\n",
    "    def forward(self, h, edge_index, gate_score):\n",
    "        row, col = edge_index\n",
    "        return self.mlp(torch.cat([h[row], h[col]], dim=-1)) * gate_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb82bb9c",
   "metadata": {},
   "source": [
    "물리법칙"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57d701f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaulingBondLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.r0_table = torch.tensor([0.0, 0.31, 0.0, 0.0, 0.0, 0.0, 0.76, 0.71, 0.66, 0.57]) \n",
    "    def forward(self, z, edge_index, dist):\n",
    "        row, col = edge_index\n",
    "        r0_i = self.r0_table.to(z.device)[z[row]]\n",
    "        r0_j = self.r0_table.to(z.device)[z[col]]\n",
    "        r0_sum = (r0_i + r0_j).unsqueeze(-1)\n",
    "        return torch.exp((r0_sum - dist) / 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8909c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StereoelectronicLayer(nn.Module):\n",
    "    def __init__(self): super().__init__()\n",
    "    def forward(self, pos_R, pos_P, edge_index):\n",
    "        row, col = edge_index\n",
    "        vec_R = F.normalize(pos_R[col] - pos_R[row], p=2, dim=-1)\n",
    "        vec_P = F.normalize(pos_P[col] - pos_P[row], p=2, dim=-1)\n",
    "        return (vec_R * vec_P).sum(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48b5fc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HSABInteractionLayer(nn.Module):\n",
    "    def __init__(self): super().__init__()\n",
    "    def forward(self, hsab, edge_index):\n",
    "        row, col = edge_index\n",
    "        mu, eta = hsab[:, 0], hsab[:, 1]\n",
    "        d_mu = (mu[row] - mu[col]).pow(2)\n",
    "        sum_eta = eta[row] + eta[col]\n",
    "        return (d_mu / (sum_eta + 1e-6)).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80ff21e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StericLayer(nn.Module):\n",
    "    def __init__(self): super().__init__()\n",
    "    def forward(self, pos, edge_index):\n",
    "        row, col = edge_index\n",
    "        dist = (pos[row] - pos[col]).norm(dim=-1)\n",
    "        density = 1.0 / (dist.pow(2) + 0.1)\n",
    "        steric = torch.zeros(pos.size(0), 1, device=pos.device)\n",
    "        steric.index_add_(0, row, density.unsqueeze(-1))\n",
    "        return steric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e67331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HammondGate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.gate = nn.Sequential(nn.Linear(3, 16), nn.SiLU(), nn.Linear(16, 1), nn.Sigmoid())\n",
    "    def forward(self, thermo): return self.gate(thermo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e2b1db",
   "metadata": {},
   "source": [
    "Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e159fca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalTimeEmbeddings(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, time):\n",
    "        device = time.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = time[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58fdf3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EGNNLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, edge_attr_dim=0):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # [수정] edge_attr_dim 추가 (R/P와의 거리 정보 입력용)\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2 + 1 + edge_attr_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "        \n",
    "        self.node_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        self.coord_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, 1, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, h, pos, edge_index, edge_attr=None):\n",
    "        row, col = edge_index\n",
    "        \n",
    "        # (1) Radial Distance (Current State)\n",
    "        coord_diff = pos[row] - pos[col]\n",
    "        radial = torch.sum(coord_diff**2, dim=1, keepdim=True)\n",
    "        \n",
    "        # (2) Edge Feature Construction\n",
    "        # [수정] edge_attr(조건 정보)가 있으면 함께 Concatenate\n",
    "        edge_feats = [h[row], h[col], radial]\n",
    "        if edge_attr is not None:\n",
    "            edge_feats.append(edge_attr)\n",
    "            \n",
    "        edge_input = torch.cat(edge_feats, dim=1)\n",
    "        msg = self.edge_mlp(edge_input)\n",
    "        \n",
    "        # (3) Coordinate Update (Equivariant)\n",
    "        trans = coord_diff * self.coord_mlp(msg)\n",
    "        agg_trans = torch.zeros_like(pos)\n",
    "        agg_trans.index_add_(0, row, trans)\n",
    "        pos_new = pos + agg_trans\n",
    "        \n",
    "        # (4) Node Feature Update\n",
    "        agg_msg = torch.zeros_like(h)\n",
    "        agg_msg.index_add_(0, row, msg)\n",
    "        node_input = torch.cat([h, agg_msg], dim=1)\n",
    "        h_new = h + self.node_mlp(node_input)\n",
    "        \n",
    "        return h_new, pos_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad7b6ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EquivariantDenoisingNetwork(nn.Module):\n",
    "    def __init__(self, node_dim, hidden_dim, num_layers=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Time Embedding\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinusoidalTimeEmbeddings(hidden_dim),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        self.emb = nn.Linear(node_dim, hidden_dim)\n",
    "        \n",
    "        # [수정] EGNNLayer에 edge_attr_dim=2 추가 (dist_to_R, dist_to_P)\n",
    "        self.layers = nn.ModuleList([\n",
    "            EGNNLayer(hidden_dim, edge_attr_dim=2) for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.final_coord_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, 1, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, h_raw, pos_t, t, edge_index, pos_R, pos_P):\n",
    "        # 1. Embeddings\n",
    "        h = self.emb(h_raw)\n",
    "        time_emb = self.time_mlp(t)\n",
    "        \n",
    "        # Time Injection (Simple addition for broadcasting)\n",
    "        # Note: In production, gather time_emb by batch index\n",
    "        # h = h + time_emb[batch_index] logic assumes implicit broadcasting or mapped externally\n",
    "        \n",
    "        # 2. Conditioning Features (Geometry-Awareness)\n",
    "        # 현재 노이즈 상태(pos_t)가 R과 P로부터 얼마나 떨어져 있는지 계산\n",
    "        row, col = edge_index\n",
    "        \n",
    "        # Edge: Distance to Reactant (relative difference projected on edge?)\n",
    "        # 더 간단하고 강력한 방법: Node별 거리를 Edge로 확장\n",
    "        # 여기서는 Edge Feature로 \"두 노드 간 거리\" 대신 \"R/P 구조에서의 거리\"를 참고하도록 함\n",
    "        \n",
    "        # (A) R/P 구조에서의 Pairwise Distance (Invariant Conditioning)\n",
    "        dist_R = (pos_R[row] - pos_R[col]).norm(dim=-1, keepdim=True)\n",
    "        dist_P = (pos_P[row] - pos_P[col]).norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        # 이를 Edge Attribute로 사용\n",
    "        cond_attr = torch.cat([dist_R, dist_P], dim=-1) # [E, 2]\n",
    "        \n",
    "        # 3. EGNN Layers\n",
    "        curr_pos = pos_t\n",
    "        curr_h = h\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            # Time embedding injection could be added inside layer, \n",
    "            # here we assume h already carries some state or we add it:\n",
    "            # curr_h = curr_h + time_emb_mapped\n",
    "            curr_h, curr_pos = layer(curr_h, curr_pos, edge_index, edge_attr=cond_attr)\n",
    "            \n",
    "        noise_pred = curr_pos - pos_t \n",
    "        return noise_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dfe4844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSDiffusionModule(nn.Module):\n",
    "    def __init__(self, node_dim, hidden_dim, timesteps=100):\n",
    "        super().__init__()\n",
    "        self.timesteps = timesteps\n",
    "        \n",
    "        # Schedule\n",
    "        beta_start, beta_end = 1e-4, 0.02\n",
    "        betas = torch.linspace(beta_start, beta_end, timesteps)\n",
    "        alphas = 1.0 - betas\n",
    "        alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "        \n",
    "        self.register_buffer('betas', betas)\n",
    "        self.register_buffer('alphas_cumprod', alphas_cumprod)\n",
    "        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))\n",
    "        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))\n",
    "        \n",
    "        self.denoise_net = EquivariantDenoisingNetwork(node_dim, hidden_dim)\n",
    "\n",
    "    def compute_loss(self, true_ts_pos, x_feat, edge_index, batch, pos_R, pos_P):\n",
    "        batch_size = batch.max().item() + 1\n",
    "        device = true_ts_pos.device\n",
    "        \n",
    "        t = torch.randint(0, self.timesteps, (batch_size,), device=device).long()\n",
    "        noise = torch.randn_like(true_ts_pos)\n",
    "        \n",
    "        t_node = t[batch]\n",
    "        sqrt_alpha = self.sqrt_alphas_cumprod[t_node].unsqueeze(-1)\n",
    "        sqrt_one_minus_alpha = self.sqrt_one_minus_alphas_cumprod[t_node].unsqueeze(-1)\n",
    "        \n",
    "        noisy_pos = sqrt_alpha * true_ts_pos + sqrt_one_minus_alpha * noise\n",
    "        \n",
    "        # Predict Noise (Conditioned on R and P)\n",
    "        noise_pred = self.denoise_net(x_feat, noisy_pos, t, edge_index, pos_R, pos_P)\n",
    "        \n",
    "        # --- [1] Active Atom Weighting ---\n",
    "        # R과 P 사이의 이동 거리가 큰 원자(반응 중심)에 더 큰 가중치 부여\n",
    "        displacement = (pos_R - pos_P).norm(dim=-1, keepdim=True) # [N, 1]\n",
    "        # 이동 거리가 0.5A 이상이면 가중치 3.0, 아니면 1.0\n",
    "        atom_weights = torch.where(displacement > 0.5, 3.0, 1.0)\n",
    "        \n",
    "        # Weighted MSE Loss (Coordinate)\n",
    "        loss_coord = (atom_weights * (noise_pred - noise) ** 2).mean()\n",
    "        \n",
    "        # --- [2] Auxiliary Distance Loss ---\n",
    "        # 예측된 노이즈로 \"복원된 구조(Denoised)\"의 거리 행렬이 \"실제 구조\"와 같아야 함\n",
    "        # x0_pred = (xt - sqrt(1-a)*eps_pred) / sqrt(a)\n",
    "        pred_x0 = (noisy_pos - sqrt_one_minus_alpha * noise_pred) / (sqrt_alpha + 1e-8)\n",
    "        \n",
    "        # Pairwise Distances\n",
    "        row, col = edge_index\n",
    "        d_pred = (pred_x0[row] - pred_x0[col]).norm(dim=-1)\n",
    "        d_true = (true_ts_pos[row] - true_ts_pos[col]).norm(dim=-1)\n",
    "        \n",
    "        loss_dist = F.mse_loss(d_pred, d_true)\n",
    "        \n",
    "        # Total Structure Loss\n",
    "        return loss_coord + 0.5 * loss_dist\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, pos_R, pos_P, x_feat, edge_index, batch):\n",
    "        # Initialization: Linear Interpolation (Better start than simple midpoint)\n",
    "        current_pos = (pos_R + pos_P) / 2.0 + torch.randn_like(pos_R) * 0.1\n",
    "        \n",
    "        for t in reversed(range(self.timesteps)):\n",
    "            batch_size = batch.max().item() + 1\n",
    "            t_batch = torch.full((batch_size,), t, device=pos_R.device, dtype=torch.long)\n",
    "            \n",
    "            # Predict\n",
    "            noise_pred = self.denoise_net(x_feat, current_pos, t_batch, edge_index, pos_R, pos_P)\n",
    "            \n",
    "            # Update\n",
    "            alpha = 1 - self.betas[t]\n",
    "            alpha_cumprod = self.alphas_cumprod[t]\n",
    "            sigma = torch.sqrt(self.betas[t])\n",
    "            \n",
    "            mean = (1 / torch.sqrt(alpha)) * (\n",
    "                current_pos - (self.betas[t] / torch.sqrt(1 - alpha_cumprod)) * noise_pred\n",
    "            )\n",
    "            \n",
    "            if t > 0:\n",
    "                noise = torch.randn_like(current_pos)\n",
    "                current_pos = mean + sigma * noise\n",
    "            else:\n",
    "                current_pos = mean\n",
    "                \n",
    "        return current_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1b0d7e",
   "metadata": {},
   "source": [
    "Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c93632c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysChemInformedPredictor(nn.Module):\n",
    "    def __init__(self, hidden_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.pauling = PaulingBondLayer()\n",
    "        self.stereo = StereoelectronicLayer()\n",
    "        self.hsab = HSABInteractionLayer()\n",
    "        self.steric = StericLayer()\n",
    "        self.hammond = HammondGate()\n",
    "        \n",
    "        self.node_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim + 4, hidden_dim), nn.SiLU(), nn.Dropout(dropout), nn.Linear(hidden_dim, 3)\n",
    "        )\n",
    "        # Edge Feats: 2H + Dist(1)*2 + Gate(1) + Pauling(3) + Stereo(1) + HSAB(1) + BDE(1) + Hammond(1) + PredD(1) = 2H + 11\n",
    "        edge_in = (hidden_dim * 2) + 11\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(edge_in, hidden_dim), nn.SiLU(), nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, 6) # Fwd(3) + Rev(3)\n",
    "        )\n",
    "\n",
    "    def forward(self, h, z, hsab, edge_index, pos_R, pos_P, gate_score, pred_delta_D, batch, thermo, bde):\n",
    "        row, col = edge_index\n",
    "        late_char = self.hammond(thermo); late_char_edge = late_char[batch[row]]\n",
    "        \n",
    "        steric_R = self.steric(pos_R, edge_index)\n",
    "        steric_graph = global_add_pool(steric_R, batch)\n",
    "        h_graph = global_add_pool(h, batch)\n",
    "        base = self.node_mlp(torch.cat([h_graph, thermo, steric_graph], dim=-1))\n",
    "        \n",
    "        dist_R = (pos_R[row]-pos_R[col]).norm(dim=-1, keepdim=True)\n",
    "        dist_P = (pos_P[row]-pos_P[col]).norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        bo_R = self.pauling(z, edge_index, dist_R)\n",
    "        bo_P = self.pauling(z, edge_index, dist_P)\n",
    "        bo_TS = (1.0 - late_char_edge) * bo_R + late_char_edge * bo_P\n",
    "        align = self.stereo(pos_R, pos_P, edge_index)\n",
    "        hsab_E = self.hsab(hsab, edge_index)\n",
    "        \n",
    "        edge_feat = torch.cat([\n",
    "            h[row], h[col], dist_R, dist_P, gate_score,\n",
    "            bo_R, bo_P, bo_TS, bde, align, late_char_edge, hsab_E, pred_delta_D\n",
    "        ], dim=-1)\n",
    "        \n",
    "        edge_out = self.edge_mlp(edge_feat) * gate_score\n",
    "        barriers = global_add_pool(edge_out, batch[row])\n",
    "        \n",
    "        return barriers[:, :3] + base, barriers[:, 3:] + base, late_char"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09d19ad",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "16cdf5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BEPGeoModel(nn.Module):\n",
    "    def __init__(self, node_dim=27, hidden_dim=256, num_layers=4):\n",
    "        super().__init__()\n",
    "        self.node_emb = nn.Linear(node_dim, hidden_dim)\n",
    "        self.diffusion = TSDiffusionModule(hidden_dim, hidden_dim)\n",
    "        self.gating = SigmoidGating(hidden_dim)\n",
    "        self.energy_predictor = PhysChemInformedPredictor(hidden_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        h = self.node_emb(data.x)\n",
    "        \n",
    "        if self.training:\n",
    "            struct_loss = self.diffusion.compute_loss(\n",
    "                data.y_pos, h, data.edge_index, data.batch, data.pos, data.pos_P\n",
    "            )\n",
    "            # Robustness: Noise Injection\n",
    "            noise_level = 0.1\n",
    "            ts_pos_input = data.y_pos + torch.randn_like(data.y_pos) * noise_level\n",
    "            \n",
    "            dist_R = (data.pos[data.edge_index[0]] - data.pos[data.edge_index[1]]).norm(dim=-1, keepdim=True)\n",
    "            dist_TS = (ts_pos_input[data.edge_index[0]] - ts_pos_input[data.edge_index[1]]).norm(dim=-1, keepdim=True)\n",
    "            pred_delta_D = dist_TS - dist_R\n",
    "\n",
    "        else:\n",
    "            struct_loss = 0.0\n",
    "            generated_ts = self.diffusion.sample(\n",
    "                data.pos, data.pos_P, h, data.edge_index, data.batch\n",
    "            )\n",
    "            ts_pos_input = generated_ts\n",
    "            \n",
    "            dist_R = (data.pos[data.edge_index[0]] - data.pos[data.edge_index[1]]).norm(dim=-1, keepdim=True)\n",
    "            dist_TS_gen = (generated_ts[data.edge_index[0]] - generated_ts[data.edge_index[1]]).norm(dim=-1, keepdim=True)\n",
    "            pred_delta_D = dist_TS_gen - dist_R\n",
    "\n",
    "        # [수정] Gating Logits 계산\n",
    "        gate_logits = self.gating(h, data.edge_index, data.pos)\n",
    "        \n",
    "        # [수정] 내부 연산용으로는 Sigmoid 적용 (0~1)\n",
    "        gate_map = torch.sigmoid(gate_logits)\n",
    "        \n",
    "        thermo_sq = data.thermo_energy.squeeze(1) \n",
    "        pred_fwd, pred_rev, ts_char = self.energy_predictor(\n",
    "            h, data.z, data.hsab, data.edge_index, data.pos, data.pos_P,\n",
    "            gate_map, pred_delta_D, data.batch, thermo_sq, data.edge_bde\n",
    "        )\n",
    "        \n",
    "        # [중요] Trainer에는 gate_logits(실수 범위)를 반환해야 BCEWithLogitsLoss 사용 가능\n",
    "        return struct_loss, pred_fwd, pred_rev, gate_logits, ts_char, pred_delta_D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a5d123",
   "metadata": {
    "id": "e9a5d123"
   },
   "source": [
    "학습루프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9da1c391",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BEPTrainer:\n",
    "    def __init__(self, model, optimizer, device, pretrain_mode=False):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        self.pretrain_mode = pretrain_mode\n",
    "        self.HARTREE_TO_KCAL = 627.5\n",
    "        \n",
    "    def train_step(self, batch):\n",
    "        self.model.train()\n",
    "        batch = batch.to(self.device)\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        # 모델 Forward (gate_logits를 받음)\n",
    "        diff_loss, pred_fwd, pred_rev, gate_logits, ts_char, pred_d = self.model(batch)\n",
    "        \n",
    "        # [안전장치] NaN 체크 - 모델이 망가졌는지 확인\n",
    "        if torch.isnan(diff_loss) or torch.isnan(gate_logits).any():\n",
    "            print(\"⚠️ Warning: NaN detected in model output. Skipping this batch.\")\n",
    "            return 0.0, torch.tensor([0.0]), torch.tensor([0.0]) # 더미 리턴\n",
    "        \n",
    "        # 1. Structure Loss\n",
    "        l_struct = diff_loss \n",
    "        \n",
    "        if self.pretrain_mode:\n",
    "            # Pre-training: 구조만 학습\n",
    "            total_loss = l_struct\n",
    "            target_fwd, pred_fwd = torch.tensor([0.0]), torch.tensor([0.0])\n",
    "            \n",
    "        else:\n",
    "            # Fine-tuning: 전체 학습\n",
    "            target_fwd = batch.y_fwd.squeeze(1) * self.HARTREE_TO_KCAL\n",
    "            target_rev = batch.y_rev.squeeze(1) * self.HARTREE_TO_KCAL\n",
    "            \n",
    "            # Gating Loss [수정됨: Logits 기반 Loss 사용]\n",
    "            # 수치적으로 훨씬 안정적이며 'input must be between 0 and 1' 에러가 발생하지 않음\n",
    "            dist_R = (batch.pos[batch.edge_index[0]] - batch.pos[batch.edge_index[1]]).norm(dim=-1, keepdim=True)\n",
    "            dist_TS_true = (batch.y_pos[batch.edge_index[0]] - batch.y_pos[batch.edge_index[1]]).norm(dim=-1, keepdim=True)\n",
    "            \n",
    "            target_gate = (torch.abs(dist_TS_true - dist_R) > 0.1).float()\n",
    "            l_gate = F.binary_cross_entropy_with_logits(gate_logits, target_gate)\n",
    "            \n",
    "            # Energy Loss\n",
    "            l_fwd = F.smooth_l1_loss(pred_fwd, target_fwd)\n",
    "            l_rev = F.smooth_l1_loss(pred_rev, target_rev)\n",
    "            \n",
    "            # 가중치 적용\n",
    "            w_struct = 2.0\n",
    "            w_gate = 1.0\n",
    "            w_energy = 0.05\n",
    "            \n",
    "            total_loss = (w_struct * l_struct) + (w_gate * l_gate) + (w_energy * (l_fwd + l_rev))\n",
    "        \n",
    "        # [안전장치] Total Loss NaN 체크\n",
    "        if torch.isnan(total_loss):\n",
    "            print(\"⚠️ Warning: Total Loss is NaN. Skipping backward.\")\n",
    "            return 0.0, torch.tensor([0.0]), torch.tensor([0.0])\n",
    "\n",
    "        total_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return total_loss.item(), target_fwd, pred_fwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6bb46840",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1767073306749,
     "user": {
      "displayName": "이예서",
      "userId": "03659744198424161652"
     },
     "user_tz": -540
    },
    "id": "6bb46840"
   },
   "outputs": [],
   "source": [
    "def run_transfer_learning(t1x_path, rgd1_path, pretrain_epochs=20, finetune_epochs=100):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Device: {device}\")\n",
    "    \n",
    "    # 모델 초기화 (한 번만 생성해서 계속 씀)\n",
    "    model = BEPGeoModel(node_dim=27, hidden_dim=256, num_layers=4).to(device)\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # [Phase 1] Pre-training on Transition1x\n",
    "    # 목적: 물리적으로 타당한 구조 생성 능력(Diffusion) 습득\n",
    "    # ---------------------------------------------------------\n",
    "    if t1x_path and os.path.exists(t1x_path):\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"🚀 Phase 1: Pre-training on Transition1x (Structure Only)\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # T1x Dataset 로드 (메모리 절약을 위해 2만개만 사용 예시)\n",
    "        t1x_dataset = Transition1xDataset(t1x_path, limit=20000)\n",
    "        t1x_loader = DataLoader(t1x_dataset, batch_size=32, shuffle=True)\n",
    "        \n",
    "        # Pre-training용 Optimizer\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "        \n",
    "        # Trainer (Pretrain Mode ON)\n",
    "        trainer = Trainer(model, optimizer, device, pretrain_mode=True)\n",
    "        \n",
    "        for epoch in range(pretrain_epochs):\n",
    "            model.train()\n",
    "            epoch_loss = 0\n",
    "            pbar = tqdm(t1x_loader, desc=f\"[Pretrain] Epoch {epoch+1}/{pretrain_epochs}\")\n",
    "            for batch in pbar:\n",
    "                try:\n",
    "                    loss, _, _ = trainer.train_step(batch)\n",
    "                    epoch_loss += loss\n",
    "                    pbar.set_postfix({'Diff_Loss': f\"{loss:.4f}\"})\n",
    "                except Exception as e:\n",
    "                    print(f\"Error in batch: {e}\")\n",
    "                    continue\n",
    "                    \n",
    "        print(\"✅ Pre-training Completed. Model learned reaction paths.\")\n",
    "        \n",
    "    else:\n",
    "        print(\"⚠️ Transition1x path not found. Skipping Phase 1.\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # [Phase 2] Fine-tuning on RGD1\n",
    "    # 목적: 실제 타겟 활성화 에너지 및 정밀 구조 예측\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"🎯 Phase 2: Fine-tuning on RGD1 (Energy + Structure)\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # RGD1 Dataset 로드 (기존 클래스 사용)\n",
    "    rgd1_dataset = ReactionDataset(rgd1_path)\n",
    "    rgd1_loader = DataLoader(rgd1_dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    # Optimizer 재설정 (Fine-tuning은 LR을 낮춰서)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "    \n",
    "    # Trainer (Pretrain Mode OFF - 이제 에너지도 학습)\n",
    "    trainer = Trainer(model, optimizer, device, pretrain_mode=False)\n",
    "    \n",
    "    history = {'loss': []}\n",
    "    real_E3 = {'H':[], 'G':[], 'E':[]}\n",
    "    pred_E3 = {'H':[], 'G':[], 'E':[]}\n",
    "    \n",
    "    for epoch in range(finetune_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        pbar = tqdm(rgd1_loader, desc=f\"[Finetune] Epoch {epoch+1}/{finetune_epochs}\")\n",
    "        \n",
    "        for batch in pbar:\n",
    "            loss, y_true, y_pred = trainer.train_step(batch)\n",
    "            epoch_loss += loss\n",
    "            pbar.set_postfix({'Total_Loss': f\"{loss:.4f}\"})\n",
    "            \n",
    "            # 마지막 Epoch 결과 저장\n",
    "            if epoch == finetune_epochs - 1:\n",
    "                r = y_true.detach().cpu().numpy()\n",
    "                p = y_pred.detach().cpu().numpy()\n",
    "                real_E3['H'].extend(r.flatten())\n",
    "                pred_E3['H'].extend(p.flatten())\n",
    "        \n",
    "        avg_loss = epoch_loss / len(rgd1_loader)\n",
    "        history['loss'].append(avg_loss)\n",
    "        scheduler.step(epoch_loss)\n",
    "\n",
    "    return history, real_E3, pred_E3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1a2af16b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 7509238,
     "status": "error",
     "timestamp": 1767080821660,
     "user": {
      "displayName": "이예서",
      "userId": "03659744198424161652"
     },
     "user_tz": -540
    },
    "id": "1a2af16b",
    "outputId": "f880fc39-9f27-45eb-fbd4-ccb6255ab2ce",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking files in: C:\\Users\\ansh1\\OneDrive\\OneDrive - personal\\서류&파일\\University of Seoul\\연구\\Code\n",
      "T1x Path: C:\\Users\\ansh1\\OneDrive\\OneDrive - personal\\서류&파일\\University of Seoul\\연구\\Code\\transition1x.h5 (Exists: True)\n",
      "RGD1 Path: C:\\Users\\ansh1\\OneDrive\\OneDrive - personal\\서류&파일\\University of Seoul\\연구\\Code\\RGD1_CHNO.h5 (Exists: True)\n",
      "\n",
      "✅ 모든 데이터셋 파일이 확인되었습니다. 전이 학습을 시작합니다.\n",
      "Device: cpu\n",
      "\n",
      "==================================================\n",
      "🚀 Phase 1: Pre-training on Transition1x (Structure Only)\n",
      "==================================================\n",
      "Loading Transition1x Data from C:\\Users\\ansh1\\OneDrive\\OneDrive - personal\\서류&파일\\University of Seoul\\연구\\Code\\transition1x.h5 (Limit: 20000)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing T1x: 100%|███████████████████████████████████████████████████████████████████| 171/171 [00:16<00:00, 10.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10073 reactions for Pre-training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Pretrain] Epoch 1/100: 100%|██████████████████████████████████████| 315/315 [01:25<00:00,  3.70it/s, Diff_Loss=1.3741]\n",
      "[Pretrain] Epoch 2/100: 100%|██████████████████████████████████████| 315/315 [01:26<00:00,  3.66it/s, Diff_Loss=1.3102]\n",
      "[Pretrain] Epoch 3/100: 100%|██████████████████████████████████████| 315/315 [01:27<00:00,  3.60it/s, Diff_Loss=1.2988]\n",
      "[Pretrain] Epoch 4/100: 100%|██████████████████████████████████████| 315/315 [01:25<00:00,  3.66it/s, Diff_Loss=1.6527]\n",
      "[Pretrain] Epoch 5/100: 100%|██████████████████████████████████████| 315/315 [01:27<00:00,  3.61it/s, Diff_Loss=1.4833]\n",
      "[Pretrain] Epoch 6/100: 100%|██████████████████████████████████████| 315/315 [01:28<00:00,  3.56it/s, Diff_Loss=1.4171]\n",
      "[Pretrain] Epoch 7/100: 100%|██████████████████████████████████████| 315/315 [01:26<00:00,  3.66it/s, Diff_Loss=1.2723]\n",
      "[Pretrain] Epoch 8/100: 100%|██████████████████████████████████████| 315/315 [01:25<00:00,  3.68it/s, Diff_Loss=1.3620]\n",
      "[Pretrain] Epoch 9/100: 100%|██████████████████████████████████████| 315/315 [01:27<00:00,  3.61it/s, Diff_Loss=1.2334]\n",
      "[Pretrain] Epoch 10/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.66it/s, Diff_Loss=1.3628]\n",
      "[Pretrain] Epoch 11/100: 100%|█████████████████████████████████████| 315/315 [01:25<00:00,  3.70it/s, Diff_Loss=1.2663]\n",
      "[Pretrain] Epoch 12/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.64it/s, Diff_Loss=1.2967]\n",
      "[Pretrain] Epoch 13/100: 100%|█████████████████████████████████████| 315/315 [01:25<00:00,  3.67it/s, Diff_Loss=1.2098]\n",
      "[Pretrain] Epoch 14/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.65it/s, Diff_Loss=1.0645]\n",
      "[Pretrain] Epoch 15/100: 100%|█████████████████████████████████████| 315/315 [01:24<00:00,  3.71it/s, Diff_Loss=1.2554]\n",
      "[Pretrain] Epoch 16/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.62it/s, Diff_Loss=1.0005]\n",
      "[Pretrain] Epoch 17/100: 100%|█████████████████████████████████████| 315/315 [01:31<00:00,  3.45it/s, Diff_Loss=1.1283]\n",
      "[Pretrain] Epoch 18/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.65it/s, Diff_Loss=1.1560]\n",
      "[Pretrain] Epoch 19/100: 100%|█████████████████████████████████████| 315/315 [01:25<00:00,  3.70it/s, Diff_Loss=1.4406]\n",
      "[Pretrain] Epoch 20/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.64it/s, Diff_Loss=0.8823]\n",
      "[Pretrain] Epoch 21/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.64it/s, Diff_Loss=1.1409]\n",
      "[Pretrain] Epoch 22/100: 100%|█████████████████████████████████████| 315/315 [01:25<00:00,  3.69it/s, Diff_Loss=1.2365]\n",
      "[Pretrain] Epoch 23/100: 100%|█████████████████████████████████████| 315/315 [01:27<00:00,  3.60it/s, Diff_Loss=1.1079]\n",
      "[Pretrain] Epoch 24/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.64it/s, Diff_Loss=1.0147]\n",
      "[Pretrain] Epoch 25/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.64it/s, Diff_Loss=0.9448]\n",
      "[Pretrain] Epoch 26/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.64it/s, Diff_Loss=0.8477]\n",
      "[Pretrain] Epoch 27/100: 100%|█████████████████████████████████████| 315/315 [01:27<00:00,  3.60it/s, Diff_Loss=1.0381]\n",
      "[Pretrain] Epoch 28/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.65it/s, Diff_Loss=1.1598]\n",
      "[Pretrain] Epoch 29/100: 100%|█████████████████████████████████████| 315/315 [01:25<00:00,  3.68it/s, Diff_Loss=1.0317]\n",
      "[Pretrain] Epoch 30/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.65it/s, Diff_Loss=1.2664]\n",
      "[Pretrain] Epoch 31/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.65it/s, Diff_Loss=1.0775]\n",
      "[Pretrain] Epoch 32/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.65it/s, Diff_Loss=1.1298]\n",
      "[Pretrain] Epoch 33/100: 100%|█████████████████████████████████████| 315/315 [01:31<00:00,  3.45it/s, Diff_Loss=1.0228]\n",
      "[Pretrain] Epoch 34/100: 100%|█████████████████████████████████████| 315/315 [01:30<00:00,  3.47it/s, Diff_Loss=1.1189]\n",
      "[Pretrain] Epoch 35/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.66it/s, Diff_Loss=1.0668]\n",
      "[Pretrain] Epoch 36/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.65it/s, Diff_Loss=0.9499]\n",
      "[Pretrain] Epoch 37/100: 100%|█████████████████████████████████████| 315/315 [01:25<00:00,  3.67it/s, Diff_Loss=1.1212]\n",
      "[Pretrain] Epoch 38/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.63it/s, Diff_Loss=0.9999]\n",
      "[Pretrain] Epoch 39/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.65it/s, Diff_Loss=0.8740]\n",
      "[Pretrain] Epoch 40/100: 100%|█████████████████████████████████████| 315/315 [01:25<00:00,  3.67it/s, Diff_Loss=1.0865]\n",
      "[Pretrain] Epoch 41/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.66it/s, Diff_Loss=0.7610]\n",
      "[Pretrain] Epoch 42/100: 100%|█████████████████████████████████████| 315/315 [01:25<00:00,  3.67it/s, Diff_Loss=0.9896]\n",
      "[Pretrain] Epoch 43/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.66it/s, Diff_Loss=0.9719]\n",
      "[Pretrain] Epoch 44/100: 100%|█████████████████████████████████████| 315/315 [01:25<00:00,  3.68it/s, Diff_Loss=0.8516]\n",
      "[Pretrain] Epoch 45/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.66it/s, Diff_Loss=0.9889]\n",
      "[Pretrain] Epoch 46/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.65it/s, Diff_Loss=0.9664]\n",
      "[Pretrain] Epoch 47/100: 100%|█████████████████████████████████████| 315/315 [01:25<00:00,  3.66it/s, Diff_Loss=0.9257]\n",
      "[Pretrain] Epoch 48/100: 100%|█████████████████████████████████████| 315/315 [01:27<00:00,  3.60it/s, Diff_Loss=0.8925]\n",
      "[Pretrain] Epoch 49/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.66it/s, Diff_Loss=1.0479]\n",
      "[Pretrain] Epoch 50/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.65it/s, Diff_Loss=0.9615]\n",
      "[Pretrain] Epoch 51/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.66it/s, Diff_Loss=1.0725]\n",
      "[Pretrain] Epoch 52/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.66it/s, Diff_Loss=1.0397]\n",
      "[Pretrain] Epoch 53/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.65it/s, Diff_Loss=0.8045]\n",
      "[Pretrain] Epoch 54/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.63it/s, Diff_Loss=0.9164]\n",
      "[Pretrain] Epoch 55/100: 100%|█████████████████████████████████████| 315/315 [01:27<00:00,  3.62it/s, Diff_Loss=0.8524]\n",
      "[Pretrain] Epoch 56/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.65it/s, Diff_Loss=0.8047]\n",
      "[Pretrain] Epoch 57/100: 100%|█████████████████████████████████████| 315/315 [01:27<00:00,  3.60it/s, Diff_Loss=0.8882]\n",
      "[Pretrain] Epoch 58/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.65it/s, Diff_Loss=0.9993]\n",
      "[Pretrain] Epoch 59/100: 100%|█████████████████████████████████████| 315/315 [01:32<00:00,  3.42it/s, Diff_Loss=1.0293]\n",
      "[Pretrain] Epoch 60/100: 100%|█████████████████████████████████████| 315/315 [01:25<00:00,  3.69it/s, Diff_Loss=0.7105]\n",
      "[Pretrain] Epoch 61/100: 100%|█████████████████████████████████████| 315/315 [01:34<00:00,  3.35it/s, Diff_Loss=0.8092]\n",
      "[Pretrain] Epoch 62/100: 100%|█████████████████████████████████████| 315/315 [01:39<00:00,  3.16it/s, Diff_Loss=0.8664]\n",
      "[Pretrain] Epoch 63/100: 100%|█████████████████████████████████████| 315/315 [01:46<00:00,  2.96it/s, Diff_Loss=0.7568]\n",
      "[Pretrain] Epoch 64/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.66it/s, Diff_Loss=0.8252]\n",
      "[Pretrain] Epoch 65/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.64it/s, Diff_Loss=0.8868]\n",
      "[Pretrain] Epoch 66/100: 100%|█████████████████████████████████████| 315/315 [01:25<00:00,  3.69it/s, Diff_Loss=1.0763]\n",
      "[Pretrain] Epoch 67/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.64it/s, Diff_Loss=0.7112]\n",
      "[Pretrain] Epoch 68/100: 100%|█████████████████████████████████████| 315/315 [01:26<00:00,  3.63it/s, Diff_Loss=0.8087]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Pretrain] Epoch 69/100: 100%|█████████████████████████████████████| 315/315 [01:25<00:00,  3.70it/s, Diff_Loss=0.8411]\n",
      "[Pretrain] Epoch 70/100: 100%|█████████████████████████████████████| 315/315 [01:33<00:00,  3.36it/s, Diff_Loss=1.1051]\n",
      "[Pretrain] Epoch 71/100: 100%|█████████████████████████████████████| 315/315 [01:33<00:00,  3.37it/s, Diff_Loss=1.1160]\n",
      "[Pretrain] Epoch 72/100: 100%|█████████████████████████████████████| 315/315 [01:38<00:00,  3.20it/s, Diff_Loss=0.8681]\n",
      "[Pretrain] Epoch 73/100: 100%|█████████████████████████████████████| 315/315 [01:32<00:00,  3.42it/s, Diff_Loss=0.8895]\n",
      "[Pretrain] Epoch 74/100: 100%|█████████████████████████████████████| 315/315 [01:40<00:00,  3.13it/s, Diff_Loss=0.8742]\n",
      "[Pretrain] Epoch 75/100: 100%|█████████████████████████████████████| 315/315 [01:28<00:00,  3.56it/s, Diff_Loss=0.7956]\n",
      "[Pretrain] Epoch 76/100: 100%|█████████████████████████████████████| 315/315 [01:43<00:00,  3.05it/s, Diff_Loss=0.9576]\n",
      "[Pretrain] Epoch 77/100: 100%|█████████████████████████████████████| 315/315 [01:29<00:00,  3.54it/s, Diff_Loss=0.9170]\n",
      "[Pretrain] Epoch 78/100: 100%|█████████████████████████████████████| 315/315 [01:33<00:00,  3.38it/s, Diff_Loss=0.9274]\n",
      "[Pretrain] Epoch 79/100: 100%|█████████████████████████████████████| 315/315 [01:53<00:00,  2.77it/s, Diff_Loss=0.9898]\n",
      "[Pretrain] Epoch 80/100: 100%|█████████████████████████████████████| 315/315 [01:37<00:00,  3.24it/s, Diff_Loss=0.9684]\n",
      "[Pretrain] Epoch 81/100: 100%|█████████████████████████████████████| 315/315 [01:48<00:00,  2.91it/s, Diff_Loss=1.0007]\n",
      "[Pretrain] Epoch 82/100: 100%|█████████████████████████████████████| 315/315 [01:41<00:00,  3.10it/s, Diff_Loss=0.7937]\n",
      "[Pretrain] Epoch 83/100: 100%|█████████████████████████████████████| 315/315 [02:13<00:00,  2.35it/s, Diff_Loss=0.7093]\n",
      "[Pretrain] Epoch 84/100: 100%|█████████████████████████████████████| 315/315 [01:38<00:00,  3.20it/s, Diff_Loss=0.7423]\n",
      "[Pretrain] Epoch 85/100: 100%|█████████████████████████████████████| 315/315 [01:28<00:00,  3.55it/s, Diff_Loss=0.9426]\n",
      "[Pretrain] Epoch 86/100: 100%|█████████████████████████████████████| 315/315 [01:32<00:00,  3.40it/s, Diff_Loss=1.0152]\n",
      "[Pretrain] Epoch 87/100: 100%|█████████████████████████████████████| 315/315 [02:01<00:00,  2.59it/s, Diff_Loss=0.9323]\n",
      "[Pretrain] Epoch 88/100: 100%|█████████████████████████████████████| 315/315 [01:24<00:00,  3.74it/s, Diff_Loss=0.8583]\n",
      "[Pretrain] Epoch 89/100: 100%|█████████████████████████████████████| 315/315 [01:25<00:00,  3.70it/s, Diff_Loss=0.8372]\n",
      "[Pretrain] Epoch 90/100: 100%|█████████████████████████████████████| 315/315 [01:25<00:00,  3.69it/s, Diff_Loss=0.8953]\n",
      "[Pretrain] Epoch 91/100: 100%|█████████████████████████████████████| 315/315 [01:24<00:00,  3.75it/s, Diff_Loss=1.0793]\n",
      "[Pretrain] Epoch 92/100: 100%|█████████████████████████████████████| 315/315 [01:24<00:00,  3.73it/s, Diff_Loss=0.8572]\n",
      "[Pretrain] Epoch 93/100: 100%|█████████████████████████████████████| 315/315 [01:24<00:00,  3.71it/s, Diff_Loss=0.8979]\n",
      "[Pretrain] Epoch 94/100: 100%|█████████████████████████████████████| 315/315 [01:24<00:00,  3.72it/s, Diff_Loss=0.7315]\n",
      "[Pretrain] Epoch 95/100: 100%|█████████████████████████████████████| 315/315 [01:23<00:00,  3.75it/s, Diff_Loss=0.8087]\n",
      "[Pretrain] Epoch 96/100: 100%|█████████████████████████████████████| 315/315 [01:24<00:00,  3.72it/s, Diff_Loss=0.8541]\n",
      "[Pretrain] Epoch 97/100: 100%|█████████████████████████████████████| 315/315 [01:24<00:00,  3.71it/s, Diff_Loss=0.8789]\n",
      "[Pretrain] Epoch 98/100: 100%|█████████████████████████████████████| 315/315 [01:23<00:00,  3.77it/s, Diff_Loss=0.7398]\n",
      "[Pretrain] Epoch 99/100: 100%|█████████████████████████████████████| 315/315 [01:24<00:00,  3.73it/s, Diff_Loss=0.9135]\n",
      "[Pretrain] Epoch 100/100: 100%|████████████████████████████████████| 315/315 [01:29<00:00,  3.51it/s, Diff_Loss=0.8017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pre-training Completed. Model learned reaction paths.\n",
      "\n",
      "==================================================\n",
      "🎯 Phase 2: Fine-tuning on RGD1 (Energy + Structure)\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Finetune] Epoch 1/200:  48%|████████████████▉                  | 2670/5531 [39:30<42:20,  1.13it/s, Total_Loss=4.3459]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✅ 모든 데이터셋 파일이 확인되었습니다. 전이 학습을 시작합니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# run_transfer_learning 함수 호출\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m hist, r_E3, p_E3 \u001b[38;5;241m=\u001b[39m \u001b[43mrun_transfer_learning\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt1x_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt1x_h5_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrgd1_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrgd1_h5_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrain_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 구조 학습 (T1x)\u001b[39;49;00m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinetune_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 에너지 학습 (RGD1)\u001b[39;49;00m\n\u001b[0;32m     24\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# 4. 결과 시각화\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hist:\n",
      "Cell \u001b[1;32mIn[45], line 74\u001b[0m, in \u001b[0;36mrun_transfer_learning\u001b[1;34m(t1x_path, rgd1_path, pretrain_epochs, finetune_epochs)\u001b[0m\n\u001b[0;32m     71\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm(rgd1_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Finetune] Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinetune_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[1;32m---> 74\u001b[0m     loss, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[0;32m     76\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mset_postfix({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal_Loss\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m})\n",
      "Cell \u001b[1;32mIn[21], line 51\u001b[0m, in \u001b[0;36mTrainer.train_step\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     47\u001b[0m     w_energy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m\n\u001b[0;32m     49\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m (w_struct \u001b[38;5;241m*\u001b[39m l_struct) \u001b[38;5;241m+\u001b[39m (w_gate \u001b[38;5;241m*\u001b[39m l_gate) \u001b[38;5;241m+\u001b[39m (w_energy \u001b[38;5;241m*\u001b[39m (l_fwd \u001b[38;5;241m+\u001b[39m l_rev))\n\u001b[1;32m---> 51\u001b[0m \u001b[43mtotal_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\ysl\\lib\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\ysl\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 1. 공통 경로 설정\n",
    "    # (사용자 환경에 맞게 수정된 경로 확인)\n",
    "    base_dir = r\"C:\\Users\\ansh1\\OneDrive\\OneDrive - personal\\서류&파일\\University of Seoul\\연구\\Code\"\n",
    "    \n",
    "    # 2. 파일 경로 생성\n",
    "    t1x_h5_path = os.path.join(base_dir, \"transition1x.h5\")  # T1x 파일명\n",
    "    rgd1_h5_path = os.path.join(base_dir, \"RGD1_CHNO.h5\")   # RGD1 파일명\n",
    "    \n",
    "    print(f\"Checking files in: {base_dir}\")\n",
    "    print(f\"T1x Path: {t1x_h5_path} (Exists: {os.path.exists(t1x_h5_path)})\")\n",
    "    print(f\"RGD1 Path: {rgd1_h5_path} (Exists: {os.path.exists(rgd1_h5_path)})\")\n",
    "\n",
    "    # [핵심 수정] T1x와 RGD1 파일이 '모두' 존재해야만 실행\n",
    "    if os.path.exists(t1x_h5_path) and os.path.exists(rgd1_h5_path):\n",
    "        print(\"\\n✅ 모든 데이터셋 파일이 확인되었습니다. 전이 학습을 시작합니다.\")\n",
    "        \n",
    "        # run_transfer_learning 함수 호출\n",
    "        hist, r_E3, p_E3 = run_transfer_learning(\n",
    "            t1x_path=t1x_h5_path, \n",
    "            rgd1_path=rgd1_h5_path, \n",
    "            pretrain_epochs=100,  # 구조 학습 (T1x)\n",
    "            finetune_epochs=200  # 에너지 학습 (RGD1)\n",
    "        )\n",
    "        \n",
    "        # 4. 결과 시각화\n",
    "        if hist:\n",
    "            plt.figure(figsize=(16, 5))\n",
    "            \n",
    "            # Loss Plot\n",
    "            plt.subplot(1, 4, 1)\n",
    "            plt.plot(hist['loss'], 'k-')\n",
    "            plt.title(\"Fine-tuning Loss\")\n",
    "            plt.xlabel(\"Epochs\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            \n",
    "            # Parity Plots (H, G, E)\n",
    "            titles, colors = [\"Delta H\", \"Delta G\", \"Delta E\"], ['r', 'g', 'b']\n",
    "            keys = ['H', 'G', 'E']\n",
    "            \n",
    "            for i, k in enumerate(keys):\n",
    "                if k in r_E3 and len(r_E3[k]) > 0:\n",
    "                    plt.subplot(1, 4, i+2)\n",
    "                    plt.scatter(r_E3[k], p_E3[k], alpha=0.3, color=colors[i], s=5)\n",
    "                    \n",
    "                    # Min/Max로 기준선 그리기\n",
    "                    mx = max(max(r_E3[k]), max(p_E3[k]))\n",
    "                    mn = min(min(r_E3[k]), min(p_E3[k]))\n",
    "                    plt.plot([mn, mx], [mn, mx], 'k--')\n",
    "                    \n",
    "                    plt.title(titles[i])\n",
    "                    plt.xlabel(\"DFT Calculation (kcal/mol)\")\n",
    "                    plt.ylabel(\"Model Prediction (kcal/mol)\")\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # 성능 리포트 출력\n",
    "            if 'print_evaluation_report' in globals():\n",
    "                print_evaluation_report(r_E3, p_E3)\n",
    "    \n",
    "    # [에러 처리] 파일이 하나라도 없으면 실행 차단\n",
    "    else:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"❌ 실행 불가: 필수 데이터셋 파일이 누락되었습니다.\")\n",
    "        print(\"=\"*50)\n",
    "        if not os.path.exists(t1x_h5_path):\n",
    "            print(f\" - [Missing] Transition1x 파일이 없습니다.\\n   경로: {t1x_h5_path}\")\n",
    "        if not os.path.exists(rgd1_h5_path):\n",
    "            print(f\" - [Missing] RGD1 파일이 없습니다.\\n   경로: {rgd1_h5_path}\")\n",
    "        print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8d30cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1767080828129,
     "user": {
      "displayName": "이예서",
      "userId": "03659744198424161652"
     },
     "user_tz": -540
    },
    "id": "7a8d30cc",
    "outputId": "878430a9-0cea-41e0-f479-2a5d7cbe467b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def print_evaluation_report(real_dict, pred_dict):\n",
    "    \"\"\"\n",
    "    학습 결과(정답 vs 예측)를 받아서 MAE, RMSE, R2, MSE를 계산하고 출력합니다.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*75)\n",
    "    print(f\"   📊 FINAL PHYSICS-INFORMED MODEL PERFORMANCE REPORT (kcal/mol)\")\n",
    "    print(\"=\"*75)\n",
    "\n",
    "    # 헤더 출력\n",
    "    header = f\"{'Energy Type':<15} | {'MAE':<10} | {'RMSE':<10} | {'MSE':<10} | {'R² Score':<10}\"\n",
    "    print(header)\n",
    "    print(\"-\" * 75)\n",
    "\n",
    "    # H, G, E 각각에 대해 계산\n",
    "    metrics = {}\n",
    "    for key in ['H', 'G', 'E']:\n",
    "        y_true = np.array(real_dict[key])\n",
    "        y_pred = np.array(pred_dict[key])\n",
    "\n",
    "        # 1. MAE (Mean Absolute Error)\n",
    "        mae = np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "        # 2. MSE (Mean Squared Error)\n",
    "        mse = np.mean((y_true - y_pred)**2)\n",
    "\n",
    "        # 3. RMSE (Root Mean Squared Error)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        # 4. R2 Score (Coefficient of Determination)\n",
    "        ss_res = np.sum((y_true - y_pred)**2)\n",
    "        ss_tot = np.sum((y_true - np.mean(y_true))**2)\n",
    "        r2 = 1 - (ss_res / (ss_tot + 1e-8)) # 0으로 나누기 방지\n",
    "\n",
    "        # 결과 저장\n",
    "        metrics[key] = {'MAE': mae, 'RMSE': rmse, 'R2': r2}\n",
    "\n",
    "        # 행 출력\n",
    "        label = f\"Delta {key} (Δ{key})\"\n",
    "        print(f\"{label:<15} | {mae:<10.4f} | {rmse:<10.4f} | {mse:<10.4f} | {r2:<10.4f}\")\n",
    "\n",
    "    print(\"=\"*75)\n",
    "\n",
    "    # [화학적 해석]\n",
    "    # 화학적 정확도(Chemical Accuracy)는 보통 1 kcal/mol 이내를 말합니다.\n",
    "    avg_mae = np.mean([metrics[k]['MAE'] for k in ['H', 'G', 'E']])\n",
    "    print(f\"⭐ Average MAE: {avg_mae:.4f} kcal/mol\")\n",
    "\n",
    "    if avg_mae < 2.5:\n",
    "        print(\"✅ 모델이 물리 법칙(BEP, Hammond, Pauling)을 매우 잘 학습했습니다!\")\n",
    "        print(\"   (일반적인 DFT 계산 오차가 2~3 kcal/mol 수준임을 감안하면 훌륭합니다.)\")\n",
    "    elif avg_mae < 5.0:\n",
    "        print(\"⚠️ 학습이 잘 되었으나, 일부 복잡한 반응에서 오차가 있습니다.\")\n",
    "    else:\n",
    "        print(\"❌ 아직 과소적합 상태이거나 물리적 제약 조건이 더 필요합니다.\")\n",
    "    print(\"=\"*75 + \"\\n\")\n",
    "\n",
    "# ==============================================================================\n",
    "# [실행 방법] main 블록 안에서 train()이 끝난 후 호출하세요\n",
    "# ==============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # 위에서 이미 train을 실행해서 r_E3, p_E3가 있다고 가정합니다.\n",
    "    # 만약 변수가 메모리에 없다면 다시 학습을 돌려야 합니다.\n",
    "\n",
    "    if 'r_E3' in locals() and 'p_E3' in locals():\n",
    "        print_evaluation_report(r_E3, p_E3)\n",
    "    else:\n",
    "        print(\"먼저 train() 함수를 실행하여 r_E3, p_E3 변수를 생성해주세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907e665d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ysl",
   "language": "python",
   "name": "ysl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
